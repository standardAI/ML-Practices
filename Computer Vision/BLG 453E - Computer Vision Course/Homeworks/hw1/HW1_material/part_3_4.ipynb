{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLG 453E - Computer Vision - Homework 1<br>Muhammed Tolga Cangöz - 150130024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.3 (SDL 2.0.16, Python 3.9.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import moviepy.editor as moviepy\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as Img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "planes = np.zeros((9,472,4,3))\n",
    "\n",
    "for i in range(1,10):\n",
    "\twith open(\"Plane_\"+str(i)+\".txt\") as f:\n",
    "\t\tcontent = f.readlines()\n",
    "\t\tfor line_id in range(len(content)):\n",
    "\t\t\tsel_line = content[line_id]\n",
    "\t\t\tsel_line = sel_line.replace(')\\n', '').replace(\"(\", '').split(\")\")\n",
    "\n",
    "\t\t\tfor point_id in range(4):\n",
    "\t\t\t\tsel_point = sel_line[point_id].split(\" \")\n",
    "\n",
    "\t\t\t\tplanes[i-1,line_id,point_id,0] = float(sel_point[0])\n",
    "\t\t\t\tplanes[i-1,line_id,point_id,1] = float(sel_point[1])\n",
    "\t\t\t\tplanes[i-1,line_id,point_id,2] = float(sel_point[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [00:21<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video part3.mp4.\n",
      "Moviepy - Writing video part3.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready part3.mp4\n"
     ]
    }
   ],
   "source": [
    "images_list = []\n",
    "vivaldi = cv2.imread('vivaldi.jpg')\n",
    "imS = cv2.resize(vivaldi, (572, 322))\n",
    "imS = cv2.flip(imS, 1)\n",
    "cat_in_the_middle = Img.open('cat-headphones.png')\n",
    "cat_in_the_middle = cat_in_the_middle.resize((572,322))\n",
    "background = cat_in_the_middle.convert(\"RGBA\")\n",
    "source_points = np.array([[0, 0], [0, 322], [572, 322], [572, 0]], dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(472)):\n",
    "\tblank_images = []\n",
    "\tblank_images_status = []\n",
    "\n",
    "\tfor j in range(0,9):\n",
    "\t\tblank_image = np.zeros((322,572,3), np.uint8)\n",
    "\n",
    "\t\tpts = planes[j,i,:,:].squeeze()[:,0:2].astype(np.int32)\n",
    "\n",
    "\t\ttemp = np.copy(pts[3,:])\n",
    "\t\tpts[3, :] = pts[2,:]\n",
    "\t\tpts[2, :] = temp\n",
    "\n",
    "\t\ttemp = np.copy(pts[0,:])\n",
    "\t\tpts[:3, ] = pts[1:, :]\n",
    "\t\tpts[3, :] = temp\n",
    "\t\t\n",
    "\t\tblank_image[:imS.shape[0], :imS.shape[1]] = imS\n",
    "\t\tM = np.array([[source_points[0][0], source_points[0][1], 1, 0, 0, 0, -source_points[0][0]*pts[0][0], -source_points[0][1]*pts[0][0]],\n",
    "\t\t\t\t\t  [source_points[1][0], source_points[1][1], 1, 0, 0, 0, -source_points[1][0]*pts[1][0], -source_points[1][1]*pts[1][0]],\n",
    "\t\t\t\t\t  [source_points[2][0], source_points[2][1], 1, 0, 0, 0, -source_points[2][0]*pts[2][0], -source_points[2][1]*pts[2][0]],\n",
    "\t\t\t\t\t  [source_points[3][0], source_points[3][1], 1, 0, 0, 0, -source_points[3][0]*pts[3][0], -source_points[3][1]*pts[3][0]],\n",
    "\t\t\t\t\t  [0, 0, 0, source_points[0][0], source_points[0][1], 1, -source_points[0][0]*pts[0][1], -source_points[0][1]*pts[0][1]],\n",
    "\t\t\t\t\t  [0, 0, 0, source_points[1][0], source_points[1][1], 1, -source_points[1][0]*pts[1][1], -source_points[1][1]*pts[1][1]],\n",
    "\t\t\t\t\t  [0, 0, 0, source_points[2][0], source_points[2][1], 1, -source_points[2][0]*pts[2][1], -source_points[2][1]*pts[2][1]],\n",
    "\t\t\t\t\t  [0, 0, 0, source_points[3][0], source_points[3][1], 1, -source_points[3][0]*pts[3][1], -source_points[3][1]*pts[3][1]]])\n",
    "\t\tInverse_M = np.linalg.pinv(M)\n",
    "\t\tpoints = np.array([pts[0][0], pts[1][0], pts[2][0], pts[3][0], pts[0][1], pts[1][1], pts[2][1], pts[3][1]])\n",
    "\t\tcoefficients = np.dot(Inverse_M, points)\n",
    "\t\ttransformationMatrix = np.concatenate([coefficients, np.array([1], dtype=np.float32)]).reshape((3,3))\n",
    "\t\tblank_image = cv2.warpPerspective(blank_image, transformationMatrix, (int(572), int(322)), flags=cv2.INTER_LINEAR)\n",
    "\t\tblank_images.append(Img.fromarray(cv2.cvtColor(blank_image, cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "\t\tif pts[2,0] < pts[1,0]:\n",
    "\t\t\tblank_images_status.append(True)\n",
    "\t\telse:\n",
    "\t\t\tblank_images_status.append(False)\n",
    "\n",
    "\tfinal_image = Img.new(\"RGBA\", background.size, \"WHITE\")\n",
    "\tfirst_time = True\n",
    "\n",
    "\tfor a in sorted(zip(blank_images, blank_images_status), key=lambda x: x[1]):\n",
    "\t\tif not a[1]:\n",
    "\t\t\topen_cv_image = np.array(a[0])\n",
    "\t\t\topen_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)\n",
    "\t\t\ttmp = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\t_,alpha = cv2.threshold(tmp,0,255, cv2.THRESH_BINARY)\n",
    "\t\t\tb, g, r = cv2.split(open_cv_image)\n",
    "\t\t\trgba = [b,g,r, alpha]\n",
    "\t\t\tdst = cv2.merge(rgba,4)\n",
    "\t\t\tfinal_image.paste(Img.fromarray(cv2.cvtColor(dst, cv2.COLOR_BGRA2RGBA)), (0,0), Img.fromarray(cv2.cvtColor(dst, cv2.COLOR_BGRA2RGBA)))\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tif first_time:\n",
    "\t\t\t\tfinal_image.paste(background, (0,0), background)\t# Adding cat in the middle\n",
    "\t\t\t\tfirst_time = False\n",
    "\t\t\topen_cv_image = np.array(a[0])\n",
    "\t\t\topen_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)\n",
    "\t\t\ttmp = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\t_,alpha = cv2.threshold(tmp,0,255,cv2.THRESH_BINARY)\n",
    "\t\t\tb, g, r = cv2.split(open_cv_image)\n",
    "\t\t\trgba = [b,g,r, alpha]\n",
    "\t\t\tdst = cv2.merge(rgba,4)\n",
    "\t\t\tfinal_image.paste(Img.fromarray(cv2.cvtColor(dst, cv2.COLOR_BGRA2RGBA)), (0,0), Img.fromarray(cv2.cvtColor(dst, cv2.COLOR_BGRA2RGBA)))\n",
    "\t\n",
    "\timages_list.append(np.array(final_image.convert('RGB')))\n",
    "\n",
    "\n",
    "clip = moviepy.ImageSequenceClip(images_list, fps = 25)\n",
    "clip.write_videofile(\"part3.mp4\", codec=\"libx264\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 4-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [00:20<00:00, 22.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video part4_60_degree_from_center.mp4.\n",
      "Moviepy - Writing video part4_60_degree_from_center.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready part4_60_degree_from_center.mp4\n"
     ]
    }
   ],
   "source": [
    "vivaldi = cv2.imread('vivaldi.jpg')\n",
    "image = cv2.flip(vivaldi, 1)\n",
    "theta = np.pi/3\n",
    "centerX = image.shape[1]/2\n",
    "centerY = image.shape[0]/2\n",
    "\n",
    "rotationMatrix = np.array([[np.cos(theta),  np.sin(theta), centerX*(1 - np.cos(theta)) - centerY*np.sin(theta)],\n",
    "                           [-np.sin(theta), np.cos(theta), centerY*(1 - np.cos(theta)) + centerX*np.sin(theta)]])\n",
    "\n",
    "# Arrange new coordinates so that new shape can be seen totally without cutting\n",
    "new_witdh = int((image.shape[0] * np.abs(rotationMatrix[0, 1])) + (image.shape[1] * np.abs(rotationMatrix[0, 0])))\n",
    "new_hight = int((image.shape[0] * np.abs(rotationMatrix[0, 0])) + (image.shape[1] * np.abs(rotationMatrix[0, 1])))\n",
    "\n",
    "# Update rotation points\n",
    "rotationMatrix[0, 2] += (new_witdh / 2) - centerX\n",
    "rotationMatrix[1, 2] += (new_hight / 2) - centerY\n",
    "\n",
    "imS =  cv2.warpAffine(image, rotationMatrix, (new_witdh, new_hight))\n",
    "\n",
    "\n",
    "images_list = []\n",
    "imS = cv2.resize(imS, (572, 322))\n",
    "cat_in_the_middle = Img.open('cat-headphones.png')\n",
    "cat_in_the_middle = cat_in_the_middle.resize((572,322))\n",
    "background = cat_in_the_middle.convert(\"RGBA\")\n",
    "source_points = np.array([[0, 0], [0, 322], [572, 322], [572, 0]], dtype=np.float32)\n",
    "\n",
    "\n",
    "for i in tqdm(range(472)):\n",
    "\tblank_images = []\n",
    "\tblank_images_status = []\n",
    "\n",
    "\tfor j in range(0,9):\n",
    "\t\tblank_image = np.zeros((322,572,3), np.uint8)\n",
    "\n",
    "\t\tpts = planes[j,i,:,:].squeeze()[:,0:2].astype(np.int32)\n",
    "\n",
    "\t\ttemp = np.copy(pts[3,:])\n",
    "\t\tpts[3, :] = pts[2,:]\n",
    "\t\tpts[2, :] = temp\n",
    "\n",
    "\t\ttemp = np.copy(pts[0,:])\n",
    "\t\tpts[:3, ] = pts[1:, :]\n",
    "\t\tpts[3, :] = temp\n",
    "\n",
    "\t\tblank_image[:imS.shape[0], :imS.shape[1]] = imS\n",
    "\t\tM = np.array([[source_points[0][0], source_points[0][1], 1, 0, 0, 0, -source_points[0][0]*pts[0][0], -source_points[0][1]*pts[0][0]],\n",
    "\t\t\t\t\t  [source_points[1][0], source_points[1][1], 1, 0, 0, 0, -source_points[1][0]*pts[1][0], -source_points[1][1]*pts[1][0]],\n",
    "\t\t\t\t\t  [source_points[2][0], source_points[2][1], 1, 0, 0, 0, -source_points[2][0]*pts[2][0], -source_points[2][1]*pts[2][0]],\n",
    "\t\t\t\t\t  [source_points[3][0], source_points[3][1], 1, 0, 0, 0, -source_points[3][0]*pts[3][0], -source_points[3][1]*pts[3][0]],\n",
    "\t\t\t\t\t  [0, 0, 0, source_points[0][0], source_points[0][1], 1, -source_points[0][0]*pts[0][1], -source_points[0][1]*pts[0][1]],\n",
    "\t\t\t\t\t  [0, 0, 0, source_points[1][0], source_points[1][1], 1, -source_points[1][0]*pts[1][1], -source_points[1][1]*pts[1][1]],\n",
    "\t\t\t\t\t  [0, 0, 0, source_points[2][0], source_points[2][1], 1, -source_points[2][0]*pts[2][1], -source_points[2][1]*pts[2][1]],\n",
    "\t\t\t\t\t  [0, 0, 0, source_points[3][0], source_points[3][1], 1, -source_points[3][0]*pts[3][1], -source_points[3][1]*pts[3][1]]])\n",
    "\t\tInverse_M = np.linalg.pinv(M)\n",
    "\t\tpoints = np.array([pts[0][0], pts[1][0], pts[2][0], pts[3][0], pts[0][1], pts[1][1], pts[2][1], pts[3][1]])\n",
    "\t\tcoefficients = np.dot(Inverse_M, points)\n",
    "\t\ttransformationMatrix = np.concatenate([coefficients, np.array([1], dtype=np.float32)]).reshape((3,3))\n",
    "\t\tblank_image = cv2.warpPerspective(blank_image, transformationMatrix, (int(572), int(322)), flags=cv2.INTER_LINEAR)\n",
    "\t\tblank_images.append(Img.fromarray(cv2.cvtColor(blank_image, cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "\t\tif pts[2,0] < pts[1,0]:\n",
    "\t\t\tblank_images_status.append(True)\n",
    "\t\telse:\n",
    "\t\t\tblank_images_status.append(False)\n",
    "\n",
    "\tfinal_image = Img.new(\"RGBA\", background.size, \"WHITE\")\n",
    "\tfirst_time = True\n",
    "\n",
    "\tfor a in sorted(zip(blank_images, blank_images_status), key=lambda x: x[1]):\n",
    "\t\tif not a[1]:\n",
    "\t\t\topen_cv_image = np.array(a[0])\n",
    "\t\t\topen_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)\n",
    "\t\t\ttmp = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\t_,alpha = cv2.threshold(tmp,0,255, cv2.THRESH_BINARY)\n",
    "\t\t\tb, g, r = cv2.split(open_cv_image)\n",
    "\t\t\trgba = [b,g,r, alpha]\n",
    "\t\t\tdst = cv2.merge(rgba,4)\n",
    "\t\t\tfinal_image.paste(Img.fromarray(cv2.cvtColor(dst, cv2.COLOR_BGRA2RGBA)), (0,0), Img.fromarray(cv2.cvtColor(dst, cv2.COLOR_BGRA2RGBA)))\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tif first_time:\n",
    "\t\t\t\tfinal_image.paste(background, (0,0), background)\n",
    "\t\t\t\tfirst_time = False\n",
    "\t\t\topen_cv_image = np.array(a[0])\n",
    "\t\t\topen_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)\n",
    "\t\t\ttmp = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\t_,alpha = cv2.threshold(tmp,0,255,cv2.THRESH_BINARY)\n",
    "\t\t\tb, g, r = cv2.split(open_cv_image)\n",
    "\t\t\trgba = [b,g,r, alpha]\n",
    "\t\t\tdst = cv2.merge(rgba,4)\n",
    "\t\t\tfinal_image.paste(Img.fromarray(cv2.cvtColor(dst, cv2.COLOR_BGRA2RGBA)), (0,0), Img.fromarray(cv2.cvtColor(dst, cv2.COLOR_BGRA2RGBA)))\n",
    "\n",
    "\timages_list.append(np.array(final_image.convert('RGB')))\n",
    "\n",
    "\n",
    "clip = moviepy.ImageSequenceClip(images_list, fps = 25)\n",
    "clip.write_videofile(\"part4_60_degree_from_center.mp4\", codec=\"libx264\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 4-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 472/472 [00:26<00:00, 17.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video part4_60_degree_from_x=0_y=0.mp4.\n",
      "Moviepy - Writing video part4_60_degree_from_x=0_y=0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready part4_60_degree_from_x=0_y=0.mp4\n"
     ]
    }
   ],
   "source": [
    "theta = np.pi/3\n",
    "rotationMatrix = np.array([[np.cos(theta),  np.sin(theta), 0],\n",
    "                           [-np.sin(theta), np.cos(theta), 0]])\n",
    "\n",
    "vivaldi = cv2.imread('vivaldi.jpg')\n",
    "image = cv2.flip(vivaldi, 1)\n",
    "w = int(image.shape[0] * abs(rotationMatrix[0, 1]) + image.shape[1] * abs(rotationMatrix[0, 0]))\n",
    "h = int(image.shape[0] * abs(rotationMatrix[0, 0]) + image.shape[1] * abs(rotationMatrix[0, 1]))\n",
    "rotationMatrix += np.asarray([[0, 0, +0], [0, 0, +1050]])  # just locating to a visible area\n",
    "imS = cv2.warpAffine(image, rotationMatrix, (w, h), borderMode=cv2.BORDER_CONSTANT)\n",
    "\n",
    "images_list = []\n",
    "imS = cv2.resize(imS, (572, 322))\n",
    "cat_in_the_middle = Img.open('cat-headphones.png')\n",
    "cat_in_the_middle = cat_in_the_middle.resize((572,322))\n",
    "background = cat_in_the_middle.convert(\"RGBA\")\n",
    "source_points = np.array([[0, 0], [0, 322], [572, 322], [572, 0]], dtype=np.float32)\n",
    "\n",
    "\n",
    "for i in tqdm(range(472)):\n",
    "\tblank_images = []\n",
    "\tblank_images_status = []\n",
    "\n",
    "\tfor j in range(0,9):\n",
    "\t\tblank_image = np.zeros((322,572,3), np.uint8)\n",
    "\n",
    "\t\tpts = planes[j,i,:,:].squeeze()[:,0:2].astype(np.int32)\n",
    "\n",
    "\t\ttemp = np.copy(pts[3,:])\n",
    "\t\tpts[3, :] = pts[2,:]\n",
    "\t\tpts[2, :] = temp\n",
    "\n",
    "\t\ttemp = np.copy(pts[0,:])\n",
    "\t\tpts[:3, ] = pts[1:, :]\n",
    "\t\tpts[3, :] = temp\n",
    "\n",
    "\t\tblank_image[:imS.shape[0], :imS.shape[1]] = imS\n",
    "\t\tM = np.array([[source_points[0][0], source_points[0][1], 1, 0, 0, 0, -source_points[0][0]*pts[0][0], -source_points[0][1]*pts[0][0]],\n",
    "\t\t\t\t\t  [source_points[1][0], source_points[1][1], 1, 0, 0, 0, -source_points[1][0]*pts[1][0], -source_points[1][1]*pts[1][0]],\n",
    "\t\t\t\t\t  [source_points[2][0], source_points[2][1], 1, 0, 0, 0, -source_points[2][0]*pts[2][0], -source_points[2][1]*pts[2][0]],\n",
    "\t\t\t\t\t  [source_points[3][0], source_points[3][1], 1, 0, 0, 0, -source_points[3][0]*pts[3][0], -source_points[3][1]*pts[3][0]],\n",
    "\t\t\t\t\t  [0, 0, 0, source_points[0][0], source_points[0][1], 1, -source_points[0][0]*pts[0][1], -source_points[0][1]*pts[0][1]],\n",
    "\t\t\t\t\t  [0, 0, 0, source_points[1][0], source_points[1][1], 1, -source_points[1][0]*pts[1][1], -source_points[1][1]*pts[1][1]],\n",
    "\t\t\t\t\t  [0, 0, 0, source_points[2][0], source_points[2][1], 1, -source_points[2][0]*pts[2][1], -source_points[2][1]*pts[2][1]],\n",
    "\t\t\t\t\t  [0, 0, 0, source_points[3][0], source_points[3][1], 1, -source_points[3][0]*pts[3][1], -source_points[3][1]*pts[3][1]]])\n",
    "\t\tInverse_M = np.linalg.pinv(M)\n",
    "\t\tpoints = np.array([pts[0][0], pts[1][0], pts[2][0], pts[3][0], pts[0][1], pts[1][1], pts[2][1], pts[3][1]])\n",
    "\t\tcoefficients = np.dot(Inverse_M, points)\n",
    "\t\ttransformationMatrix = np.concatenate([coefficients, np.array([1], dtype=np.float32)]).reshape((3,3))\n",
    "\t\tblank_image = cv2.warpPerspective(blank_image, transformationMatrix, (int(572), int(322)), flags=cv2.INTER_LINEAR)\n",
    "\t\tblank_images.append(Img.fromarray(cv2.cvtColor(blank_image, cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "\t\tif pts[2,0] < pts[1,0]:\n",
    "\t\t\tblank_images_status.append(True)\n",
    "\t\telse:\n",
    "\t\t\tblank_images_status.append(False)\n",
    "\n",
    "\tfinal_image = Img.new(\"RGBA\", background.size, \"WHITE\")\n",
    "\tfirst_time = True\n",
    "\n",
    "\tfor a in sorted(zip(blank_images, blank_images_status), key=lambda x: x[1]):\n",
    "\t\tif not a[1]:\n",
    "\t\t\topen_cv_image = np.array(a[0])\n",
    "\t\t\topen_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)\n",
    "\t\t\ttmp = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\t_,alpha = cv2.threshold(tmp,0,255, cv2.THRESH_BINARY)\n",
    "\t\t\tb, g, r = cv2.split(open_cv_image)\n",
    "\t\t\trgba = [b,g,r, alpha]\n",
    "\t\t\tdst = cv2.merge(rgba,4)\n",
    "\t\t\tfinal_image.paste(Img.fromarray(cv2.cvtColor(dst, cv2.COLOR_BGRA2RGBA)), (0,0), Img.fromarray(cv2.cvtColor(dst, cv2.COLOR_BGRA2RGBA)))\n",
    "\t\t\n",
    "\t\telse:\n",
    "\t\t\tif first_time:\n",
    "\t\t\t\tfinal_image.paste(background, (0,0), background)\n",
    "\t\t\t\tfirst_time = False\n",
    "\t\t\topen_cv_image = np.array(a[0])\n",
    "\t\t\topen_cv_image = cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)\n",
    "\t\t\ttmp = cv2.cvtColor(open_cv_image, cv2.COLOR_BGR2GRAY)\n",
    "\t\t\t_,alpha = cv2.threshold(tmp,0,255,cv2.THRESH_BINARY)\n",
    "\t\t\tb, g, r = cv2.split(open_cv_image)\n",
    "\t\t\trgba = [b,g,r, alpha]\n",
    "\t\t\tdst = cv2.merge(rgba,4)\n",
    "\t\t\tfinal_image.paste(Img.fromarray(cv2.cvtColor(dst, cv2.COLOR_BGRA2RGBA)), (0,0), Img.fromarray(cv2.cvtColor(dst, cv2.COLOR_BGRA2RGBA)))\n",
    "\n",
    "\timages_list.append(np.array(final_image.convert('RGB')))\n",
    "\n",
    "\n",
    "clip = moviepy.ImageSequenceClip(images_list, fps = 25)\n",
    "clip.write_videofile(\"part4_60_degree_from_x=0_y=0.mp4\", codec=\"libx264\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are the same."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ded493e77ac558c5a79f920bf5303ffe5196fd5a596f10e0f3cd289e09f67573"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pt': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
