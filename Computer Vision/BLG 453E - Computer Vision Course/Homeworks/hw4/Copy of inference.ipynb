{"cells":[{"cell_type":"markdown","metadata":{},"source":["BLG 453E - Computer Vision<br>Homework 4<br>Muhammed Tolga Cang√∂z<br>150130024"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6749,"status":"ok","timestamp":1643521180597,"user":{"displayName":"Yusuf Huseyin Sahin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj348YW3DftvGjH4bapfEVXPyfn2uOHWE7lht_tbA=s64","userId":"11880392837456954132"},"user_tz":-180},"id":"8wjYOxdBU9TH","outputId":"88a2a092-f61b-4e8e-82b9-5a70c4d5124d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (1.10.2.3)\n","Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n","Requirement already satisfied: torch==1.10.2+cu113 in /usr/local/lib/python3.7/dist-packages (1.10.2+cu113)\n","Requirement already satisfied: torchvision==0.11.3+cu113 in /usr/local/lib/python3.7/dist-packages (0.11.3+cu113)\n","Requirement already satisfied: torchaudio==0.10.2+cu113 in /usr/local/lib/python3.7/dist-packages (0.10.2+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.2+cu113) (3.10.0.2)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.3+cu113) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.3+cu113) (1.19.5)\n"]}],"source":["!pip install ninja\n","!pip3 install torch==1.10.2+cu113 torchvision==0.11.3+cu113 torchaudio==0.10.2+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n","\n","\n","\n"," "]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3349,"status":"ok","timestamp":1643521187666,"user":{"displayName":"Yusuf Huseyin Sahin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj348YW3DftvGjH4bapfEVXPyfn2uOHWE7lht_tbA=s64","userId":"11880392837456954132"},"user_tz":-180},"id":"jl27gdbJU_M5","outputId":"d781fe8c-a7ba-4cfd-b61b-12001f51160c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":12212,"status":"ok","timestamp":1643521203972,"user":{"displayName":"Yusuf Huseyin Sahin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj348YW3DftvGjH4bapfEVXPyfn2uOHWE7lht_tbA=s64","userId":"11880392837456954132"},"user_tz":-180},"id":"rWehk_ETJ72F","outputId":"61b927b4-0749-4a7b-b532-0c1606922fe0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading pSp from checkpoint: pretrained_models/psp_ffhq_encode.pt\n"]}],"source":["import os\n","from argparse import Namespace\n","\n","import numpy as np\n","import torch\n","import sys\n","import dlib\n","sys.path.append(\".\")\n","sys.path.append(\"..\")\n","\n","from options.test_options import TestOptions\n","from models.psp import pSp\n","import cv2\n","from scripts.align_all_parallel import align_face\n","import torchvision.transforms as transforms\n","\n","#test_opts = TestOptions().parse()\n","\n","test_opts = Namespace(checkpoint_path=None, couple_outputs=False, data_path='gt_images', exp_dir=None, latent_mask=None, mix_alpha=None, n_images=None, n_outputs_to_generate=5, resize_factors=None, resize_outputs=False, test_batch_size=2, test_workers=2)\n","\n","\n","test_opts.checkpoint_path = 'pretrained_models/psp_ffhq_encode.pt'\n","\n","\n","# update test options with options used during training\n","ckpt = torch.load(test_opts.checkpoint_path, map_location='cpu')\n","opts = ckpt['opts']\n","opts.update(vars(test_opts))\n","opts['output_size'] = 1024\n","\n","opts = Namespace(**opts)\n","\n","\n","\n","net = pSp(opts)\n","net.eval()\n","net.cuda()\n","#Prepare the PSPNet + StyleGAN network\n","\n","transform = transforms.Compose([\n","\ttransforms.Resize(size=(256, 256)),\n","\ttransforms.ToTensor(),\n","\ttransforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]\n",")\n","#Preprocessing operations for each image\n","\n","predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n","#Predict facial landmarks\n","\n","aligned_image1 = align_face(filepath=\"nuri.jpg\", predictor=predictor)\n","aligned_image1 = aligned_image1.convert(\"RGB\")\n","# Align face using the landmarks\n","\n","from_im1 = transform(aligned_image1).unsqueeze(0)\n","# Do preprocessing on the aligned face\n","\n","aligned_image2 = align_face(filepath=\"albert.jpeg\", predictor=predictor)\n","aligned_image2 = aligned_image2.convert(\"RGB\")\n","# Align face using the landmarks\n","\n","from_im2 = transform(aligned_image2).unsqueeze(0)\n","# Do preprocessing on the aligned face\n","\n","with torch.no_grad():\n","\tinput1 = from_im1.float().cuda()\n","\t_, latent_vector1 = net(input1, randomize_noise=False, resize=False, return_latents=True)\n","\tinput2 = from_im2.float().cuda()\n","\t_, latent_vector2 = net(input2, randomize_noise=False, resize=False, return_latents=True)\n","\t# Obtain features from input image\n","\n","\tfor i in range(101):\n","\t\tz3 = ((100-i)/100)*latent_vector1 + (i/100)*latent_vector2\n","\t\timg3, _ = net.decoder([z3.float()],input_is_latent=True, randomize_noise=False, return_latents=False)\n","\t\tresult = img3.squeeze().permute((1,2,0)).cpu().numpy()\n","\n","\t\tresult[result>1] = 1\n","\t\tresult[result<-1] = -1\n","\t\tresult = (255*(result+1)//2).astype(np.uint8)\n","\n","\t\tcv2.imwrite(\"results/result_{:03d}.png\".format(i), result[:,:,[2,1,0]])\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Moviepy - Building video part3_video.mp4.\n","Moviepy - Writing video part3_video.mp4\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                             \r"]},{"name":"stdout","output_type":"stream","text":["Moviepy - Done !\n","Moviepy - video ready part3_video.mp4\n"]}],"source":["import moviepy.editor as mpy\n","\n","clip = mpy.ImageSequenceClip(os.path.join(\"results/\"), fps=10)\n","clip.write_videofile('part3_video.mp4')"]}],"metadata":{"accelerator":"GPU","colab":{"name":"Copy of inference.ipynb","provenance":[]},"interpreter":{"hash":"d88a76ab6370ecc75972e9b317bd0eac4389d28241f69fa7f9a5bfb7fe1e7e4a"},"kernelspec":{"display_name":"Python 2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":0}
