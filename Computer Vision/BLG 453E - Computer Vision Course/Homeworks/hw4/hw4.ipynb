{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLG 453E - Computer Vision<br>Homework 4<br>Muhammed Tolga Cang√∂z<br>150130024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import moviepy.editor as mpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(0, 455, 5):\n",
    "    img1 = plt.imread(\"DJI_0101/{:05d}.png\".format(k))\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
    "    img2 = plt.imread(\"DJI_0101/{:05d}.png\".format(k+5))\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    img1 /= 255.0\n",
    "    img2 /= 255.0\n",
    "    window_size = 5\n",
    "    threshold = 0.000001\n",
    "    filterX = np.array([[-1., 1.], \n",
    "                        [-1., 1.]])\n",
    "    filterY = np.array([[-1., -1.], \n",
    "                        [1., 1.]])\n",
    "    filterT = np.array([[1., 1.], \n",
    "                        [1., 1.]])\n",
    "    ws = int(window_size/2)\n",
    "    \n",
    "    # Derivatives of the images in the direction of x\n",
    "    fx = cv2.filter2D(img1, -1, cv2.flip(filterX, -1), borderType=cv2.BORDER_REFLECT)\n",
    "    # Derivatives of the images in the direction of y\n",
    "    fy = cv2.filter2D(img1, -1, cv2.flip(filterY, -1), borderType=cv2.BORDER_REFLECT)\n",
    "    # ft means the difference between the two consecutive images (in time), ft = img2 - img1\n",
    "    ft = cv2.filter2D(img2, -1, cv2.flip(filterT, -1), borderType=cv2.BORDER_REFLECT) +\\\n",
    "        cv2.filter2D(img1, -1, cv2.flip(-filterT, -1), borderType=cv2.BORDER_REFLECT)\n",
    "    u, v = np.zeros_like(img1), np.zeros_like(img1)\n",
    "    \n",
    "    for i in range(ws, img1.shape[0] - ws):\n",
    "        for j in range(ws, img1.shape[1] - ws):\n",
    "            Ix, Iy = fx[i - ws: i + ws + 1, j - ws: j + ws + 1].flatten(), fy[i - ws:i + ws + 1, j - ws:j + ws + 1].flatten()\n",
    "            b  = ft[i - ws:i + ws + 1, j - ws: j + ws + 1].reshape(window_size*window_size, 1)\n",
    "            A  = np.transpose(np.vstack((Ix, Iy)))\n",
    "            # If there is enough information to estimate the flow, the least square method is used\n",
    "            if np.sort(np.abs(np.linalg.eigvals(A.T.dot(A))))[0] >= threshold:\n",
    "                u[i,j], v[i,j] = np.linalg.pinv(A.T.dot(A)).dot(A.T).dot(b)\n",
    "\n",
    "    U = np.abs(u) + np.abs(v)\n",
    "    thresh_image = cv2.threshold(U, 2, 255, 0)[1].astype(np.uint8)\n",
    "    a = cv2.findContours(thresh_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    center_points = []\n",
    "    for c in a[0]:\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] != 0:\n",
    "            centerX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            centerY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        else:\n",
    "            continue\n",
    "        center_points.append([centerY, centerX])\n",
    "    \n",
    "    # Mainly, there are two blobs moving in the pictures, the left one and the right one.\n",
    "    blob1 = center_points[0]\n",
    "    blob2 = center_points[-1]\n",
    "    color = (0, 255, 0) # Green color in BGR for arrowed line\n",
    "    thickness = 5\n",
    "\n",
    "    start_point = blob1[0], blob1[1]\n",
    "    end_point = blob1[0] + int(10*v[blob1[0], blob1[1]]), blob1[1] + int(10*u[blob1[0], blob1[1]])\n",
    "    img2 = plt.imread(\"DJI_0101/{:05d}.png\".format(k+5))\n",
    "    image = cv2.arrowedLine(cv2.cvtColor(img2, cv2.COLOR_RGB2BGR), start_point[::-1], end_point[::-1], color, thickness)\n",
    "\n",
    "\n",
    "    start_point = blob2[0], blob2[1]\n",
    "    end_point = blob2[0] + int(10*v[blob2[0], blob2[1]]), blob2[1] + int(10*u[blob2[0], blob2[1]])\n",
    "    image = cv2.arrowedLine(cv2.cvtColor(image, cv2.COLOR_RGB2BGR), start_point[::-1], end_point[::-1], color, thickness)\n",
    "    image[image == 255] = 1\n",
    "\n",
    "    plt.imsave(\"part1/{:05d}.png\".format(k), (image*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = mpy.ImageSequenceClip(os.path.join(\"part1/\"), fps=10)\n",
    "clip.write_videofile('part1_video.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = []\n",
    "# Choosing first image as a reference point\n",
    "reference = plt.imread(\"DJI_0101/00000.png\")\n",
    "reference_gray = cv2.cvtColor(reference, cv2.COLOR_RGB2GRAY)\n",
    "reference_gray = cv2.GaussianBlur(reference_gray, (21, 21), 0)\n",
    "\n",
    "\n",
    "for i in range(1, 460):\n",
    "    each_frame = plt.imread(\"DJI_0101/%05d.png\" % i)\n",
    "    \n",
    "    gray = cv2.cvtColor(each_frame, cv2.COLOR_RGB2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "    # Take differences between the reference and the next frame\n",
    "    difference = cv2.absdiff(gray, reference_gray)\n",
    "    # Remove noise a bit\n",
    "    thresh = cv2.threshold(difference, 0.075, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    \n",
    "    images_list.append(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(images_list)):\n",
    "    plt.imsave(\"part2/%05d.png\" % i, images_list[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = mpy.ImageSequenceClip(os.path.join(\"part2/\"), fps=24)\n",
    "clip.write_videofile('part2_video.mp4')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d88a76ab6370ecc75972e9b317bd0eac4389d28241f69fa7f9a5bfb7fe1e7e4a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('th': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
